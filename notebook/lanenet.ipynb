{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import pdb\n",
    "\n",
    "# supporting:\n",
    "\n",
    "sys.path.insert(0,'..')\n",
    "from config import global_config\n",
    "from dataset import LaneNetDataset\n",
    "from model import vgg_encoder\n",
    "from model import fcn_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mainly loss calculation and inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_rgb(rgb, cuda=True):\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225])\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize])\n",
    "    \n",
    "    rgb_tensor = preprocess(rgb)\n",
    "    \n",
    "    # have to check if batch or not\n",
    "    if len(rgb_tensor) != 4:\n",
    "        rgb_tensor = rgb_tensor.unsqueeze(0)\n",
    "    \n",
    "    if cuda:\n",
    "        rgb_tensor = rgb_tensor.cuda()\n",
    "    \n",
    "    return rgb_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneNet(nn.Module):\n",
    "\n",
    "    def __init__(self, use_cuda=True):\n",
    "        super(LaneNet, self).__init__()\n",
    "        self.encoder = vgg_encoder.VGGEncoder()\n",
    "        self.decoder = fcn_decoder.FCNDecoder()\n",
    "        self.conv1 = nn.Conv2d(64, 3, kernel_size=1, bias=False)  # pixembedding\n",
    "        self.entropy = nn.CrossEntropyLoss()\n",
    "        print(use_cuda)\n",
    "        self.use_cuda = use_cuda\n",
    "    \n",
    "    def forward(self, src):\n",
    "        # encode\n",
    "        ret = self.encoder(src)\n",
    "        # decode\n",
    "        decode_logits, decode_deconv  = self.decoder(ret)\n",
    "        return (decode_logits, decode_deconv)\n",
    "\n",
    "    def inference(self, src):\n",
    "        decode_logits, decode_deconv  = self.forward(src)\n",
    "        \n",
    "        binary_seg_ret = F.softmax(decode_logits)\n",
    "        binary_seg_ret = np.argmax(binary_seg_ret, dim=1)\n",
    "        \n",
    "        pix_embedding = F.relu(self.conv1(decode_deconv))\n",
    "        return (binary_seg_ret, pix_embedding) \n",
    "    \n",
    "    def compute_loss(self, src, binary, instance):\n",
    "        decode_logits, decode_deconv  = self.forward(src)\n",
    "\n",
    "        # step 1:\n",
    "        # calculate loss between binary and decode logits\n",
    "        #\n",
    "        # use softmax_cross_entropy\n",
    "        decode_logits_reshape = decode_logits.view([decode_logits.shape[0], \n",
    "                                                    decode_logits.shape[1], \n",
    "                                                    decode_logits.shape[2] * decode_logits.shape[3]])\n",
    "        binary_reshape = binary.view(binary.shape[0],\n",
    "                                     binary.shape[1]*binary.shape[2])\n",
    "        binary_reshape = torch.div(binary_reshape, 255)\n",
    "        binary_reshape = binary_reshape.long()\n",
    "\n",
    "        binary_segmentation_loss = self.entropy(decode_logits_reshape, binary_reshape)\n",
    "\n",
    "        # step 2:\n",
    "        # calculate discrimitive loss between deconv and instance\n",
    "        # change deconv into pix_embedding\n",
    "        pix_embedding = F.relu(self.conv1(decode_deconv))\n",
    "        # then calculate discrimitive loss\n",
    "        disc_loss, l_var, l_dist, l_reg = \\\n",
    "                self.discriminative_loss(pix_embedding, instance, 0.5, 1.5, 1.0, 1.0, 0.001)\n",
    "        \n",
    "        total_loss = 0.7*binary_segmentation_loss + 0.3*disc_loss\n",
    "        \n",
    "        return total_loss, binary_segmentation_loss, pix_embedding, disc_loss\n",
    "        \n",
    "    def discriminative_loss(self, prediction, correct_label,\n",
    "                        delta_v, delta_d, param_var, param_dist, param_reg):\n",
    "        \n",
    "        # saving list (maybe implement dynamic tensor?)\n",
    "        output_ta_loss = []\n",
    "        output_ta_var = []\n",
    "        output_ta_dist = []\n",
    "        output_ta_reg = []\n",
    "        \n",
    "        # for each batch calculate the loss\n",
    "        i = 0\n",
    "        while i < prediction.shape[0]:\n",
    "            # calculate discrimitive loss for single image\n",
    "            single_prediction = prediction[i]\n",
    "            single_label = correct_label[i]\n",
    "            # pdb.set_trace()\n",
    "            disc_loss, l_var, l_dist, l_reg = self.discriminative_loss_single(\n",
    "                single_prediction, single_label, delta_v, delta_d, param_var, param_dist, param_reg)\n",
    "            \n",
    "            output_ta_loss.append(disc_loss.unsqueeze(0))\n",
    "            output_ta_var.append(l_var.unsqueeze(0))\n",
    "            output_ta_dist.append(l_dist.unsqueeze(0))\n",
    "            output_ta_reg.append(l_reg.unsqueeze(0))\n",
    "            \n",
    "            i += 1  # next image in batch\n",
    "        \n",
    "        out_loss_op = torch.cat(output_ta_loss)\n",
    "        out_var_op = torch.cat(output_ta_var)\n",
    "        out_dist_op = torch.cat(output_ta_dist)\n",
    "        out_reg_op = torch.cat(output_ta_reg)\n",
    "        \n",
    "        # calculate mean of the batch\n",
    "        disc_loss = out_loss_op.mean()\n",
    "        l_var = out_var_op.mean()\n",
    "        l_dist = out_dist_op.mean()\n",
    "        l_reg = out_reg_op.mean()\n",
    "\n",
    "        return disc_loss, l_var, l_dist, l_reg\n",
    "        \n",
    "    def discriminative_loss_single(\n",
    "            self,\n",
    "            prediction,\n",
    "            correct_label,\n",
    "            delta_v,\n",
    "            delta_d,\n",
    "            param_var,\n",
    "            param_dist,\n",
    "            param_reg):\n",
    "        '''\n",
    "        The example partition loss function mentioned in the paper equ(1)\n",
    "        :param prediction: inference of network\n",
    "        :param correct_label: instance label\n",
    "        :param delta_v: cutoff variance distance\n",
    "        :param delta_d: curoff cluster distance\n",
    "        :param param_var: weight for intra cluster variance\n",
    "        :param param_dist: weight for inter cluster distances\n",
    "        :param param_reg: weight regularization\n",
    "        '''\n",
    "        \n",
    "        feature_dim = prediction.shape[0]\n",
    "        # Make it a single line\n",
    "        correct_label = correct_label.view([correct_label.shape[0] * correct_label.shape[1]]).float()\n",
    "        reshaped_pred = prediction.view([feature_dim, prediction.shape[1] * prediction.shape[2]]).float()\n",
    "        \n",
    "        # Get unique labels\n",
    "        unique_labels, unique_id = torch.unique(correct_label, sorted=True, return_inverse=True)\n",
    "        ids, counts = np.unique(unique_id, return_counts=True)\n",
    "        num_instances = len(counts)\n",
    "        counts = torch.tensor(counts, dtype=torch.float32)\n",
    "        if self.use_cuda:\n",
    "            counts = counts.cuda()\n",
    "        \n",
    "        # Calculate the pixel embedding mean vector\n",
    "        if self.use_cuda:\n",
    "            segmented_sum = torch.zeros(feature_dim, num_instances).cuda().scatter_add(1, unique_id.repeat([feature_dim,1]), reshaped_pred)\n",
    "        else:\n",
    "            segmented_sum = torch.zeros(feature_dim, num_instances).scatter_add(1, unique_id.repeat([feature_dim,1]), reshaped_pred)\n",
    "        \n",
    "        mu = torch.div(segmented_sum, counts)\n",
    "        mu_expand = torch.gather(mu, 1, unique_id.repeat([feature_dim,1]))\n",
    "\n",
    "        # Calculate loss(var)\n",
    "        distance = (mu_expand - reshaped_pred).t().norm(dim=1)\n",
    "        distance -= delta_v\n",
    "        distance = torch.clamp(distance, min=0.)   # min is 0.\n",
    "        distance = distance.pow(2)\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            l_var = torch.zeros(num_instances).cuda().scatter_add(0, unique_id, distance)\n",
    "        else:\n",
    "            l_var = torch.zeros(num_instances).scatter_add(0, unique_id, distance)\n",
    "        l_var = torch.div(l_var, counts)\n",
    "        l_var = l_var.sum()\n",
    "        l_var = torch.div(l_var, num_instances)  # single value \n",
    "   \n",
    "        # Calculate the loss(dist) of the formula\n",
    "        mu_diff = []\n",
    "        for i in range(feature_dim):\n",
    "            for j in range(feature_dim):\n",
    "                if i != j:\n",
    "                    diff = mu[i] - mu[j]\n",
    "                    mu_diff.append(diff.unsqueeze(0))\n",
    "                    \n",
    "        mu_diff = torch.cat(mu_diff)\n",
    "        \n",
    "        mu_norm = mu_diff.norm(dim=1)\n",
    "        mu_norm = (2. * delta_d - mu_norm)\n",
    "        mu_norm = torch.clamp(mu_norm, min=0.)\n",
    "        mu_norm = mu_norm.pow(2)\n",
    "        \n",
    "        l_dist = mu_norm.mean()\n",
    "        \n",
    "        # Calculate the regular term loss mentioned in the original Discriminative Loss paper\n",
    "        l_reg = mu.norm(dim=1).mean()\n",
    "\n",
    "        # Consolidation losses are combined according to the parameters mentioned in the original Discriminative Loss paper\n",
    "        param_scale = 1.\n",
    "        l_var = param_var * l_var\n",
    "        l_dist = param_dist * l_dist\n",
    "        l_reg = param_reg * l_reg\n",
    "\n",
    "        loss = param_scale * (l_var + l_dist + l_reg)\n",
    "\n",
    "        return loss, l_var, l_dist, l_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from config import global_config\n",
    "from dataset import LaneNetDataset\n",
    "\n",
    "TRAIN_FILE = '/home/ubuntu/dev/LaneNet-Pytorch/data/training_data/train.txt'\n",
    "CFG = global_config.cfg\n",
    "\n",
    "dataset = LaneNetDataset(TRAIN_FILE, CFG)\n",
    "inputs = next(iter(dataset))  # (src, binary, instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "lane_net = LaneNet(use_cuda=False)\n",
    "\n",
    "src = preprocess_rgb(inputs[0], cuda=False)\n",
    "binary = torch.tensor(inputs[1]).unsqueeze(0)\n",
    "instance = torch.tensor(inputs[2]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss, binary_segmentation_loss, pix_embedding, disc_loss = lane_net.compute_loss(src, binary, instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1845, grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
